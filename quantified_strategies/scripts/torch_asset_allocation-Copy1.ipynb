{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74dbfda-6af3-4c9f-9f4d-f2b02af907c4",
   "metadata": {},
   "source": [
    "# Asset Allocation with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7c1dd-46c4-41af-bbaf-1ddaed2dfb1a",
   "metadata": {},
   "source": [
    " Goal of this notebook is to create a model to combine the signals from the various strategies to create an asset allocation neural network to outperform equally weighted, as Markowitz may not be appropriate as the signals may be to buy or sell the same asset therefore yielding a perfect correlation when active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3ae61a-abfa-4ecb-8162-123fbb04ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import typing as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b95f022-e5cb-4aac-944b-22e1facf9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantified_strategies import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4360c77f-d75d-4eb4-b4b2-3127d322b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASH = \"CASH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb4ed6d7-f5ad-4c66-b3b6-06c3fac13d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPY']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASSETS = [\"SPY\", CASH]\n",
    "ASSETS = [\"SPY\"]\n",
    "ASSETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387b494-383f-4e11-b4a3-fc64f9193657",
   "metadata": {},
   "source": [
    "## Dataset Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e97493-d54b-4913-997d-2ad66f35a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(assets: str | t.List[str], is_classification: bool = True) -> t.Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    def get_y() -> pd.DataFrame:\n",
    "        price_data = [utils.get_data(ticker=ticker, columns=\"Adj Close\").to_frame(name=ticker) for ticker in assets if ticker != \"CASH\"]\n",
    "        price_data = pd.concat(price_data, axis=1)\n",
    "        return_data = price_data.pct_change()\n",
    "        if \"CASH\" in assets:\n",
    "            return_data[\"CASH\"] = 0.0\n",
    "        return_data = return_data.shift(-1)\n",
    "        return_data = return_data.dropna()\n",
    "\n",
    "        if is_classification:\n",
    "            return (return_data > 0).astype(int)\n",
    "        \n",
    "        return return_data\n",
    "\n",
    "    def get_X() -> pd.DataFrame:\n",
    "        strategy_returns = pd.read_csv(f\"outputs/strategy_returns.csv\", index_col=0, header=[0, 1, 2])\n",
    "        strategy_returns = strategy_returns.loc[:, strategy_returns.columns.get_level_values(2).isin(assets)]\n",
    "        strategy_returns.index = pd.DatetimeIndex(strategy_returns.index)\n",
    "        is_active = ~(strategy_returns.isna())\n",
    "        is_active = is_active.astype(int)\n",
    "        return is_active\n",
    "\n",
    "    assets = assets if isinstance(assets, list) else [assets]\n",
    "\n",
    "    # Get target variables: these are the returns from entering a position from close to close t+1\n",
    "    y = get_y()\n",
    "    \n",
    "    # Get explanatory variables: these are the signals from the strategies indicating whether to buy or not\n",
    "    X = get_X()\n",
    "\n",
    "    ret_t_minus_1 = y.rename(columns={col: f\"{col}_ret_t_minus_1\" for col in y.columns})\n",
    "    ret_t_minus_1 = ret_t_minus_1.shift(1).fillna(0.0)\n",
    "    X = pd.concat([X, ret_t_minus_1], axis=1)\n",
    "    X = X.dropna()\n",
    "\n",
    "    X = X.loc[X.index.isin(X.index.intersection(y.index))]\n",
    "    y = y.loc[y.index.isin(y.index.intersection(X.index))]\n",
    "\n",
    "    X = X.sort_index()\n",
    "    y = y.sort_index()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "orig_X_total, orig_y_total = get_data(assets=ASSETS, is_classification=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7fd96d-bf99-403b-bb45-f30d856f9597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_X_total.shape = (6072, 9)\n",
      "orig_y_total.shape = (6072, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{orig_X_total.shape = }\")\n",
    "print(f\"{orig_y_total.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc30e9ec-6998-45a3-b92f-14cd77a34e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(event_trading, super_bowl, SPY)</th>\n",
       "      <th>(overnight_trading, short_term_reversal, SPY)</th>\n",
       "      <th>(seasonal_trading, buy_when_yields_are_low, SPY)</th>\n",
       "      <th>(seasonal_trading, pay_day_strategy, SPY)</th>\n",
       "      <th>(seasonal_trading, santa_claus_strategy, SPY)</th>\n",
       "      <th>(seasonal_trading, september_bear, SPY)</th>\n",
       "      <th>(seasonal_trading, tax_day_strategy, SPY)</th>\n",
       "      <th>(seasonal_trading, turn_around_tuesday_strategy, SPY)</th>\n",
       "      <th>SPY_ret_t_minus_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            (event_trading, super_bowl, SPY)  \\\n",
       "Date                                           \n",
       "2000-01-03                               0.0   \n",
       "\n",
       "            (overnight_trading, short_term_reversal, SPY)  \\\n",
       "Date                                                        \n",
       "2000-01-03                                            0.0   \n",
       "\n",
       "            (seasonal_trading, buy_when_yields_are_low, SPY)  \\\n",
       "Date                                                           \n",
       "2000-01-03                                               0.0   \n",
       "\n",
       "            (seasonal_trading, pay_day_strategy, SPY)  \\\n",
       "Date                                                    \n",
       "2000-01-03                                        1.0   \n",
       "\n",
       "            (seasonal_trading, santa_claus_strategy, SPY)  \\\n",
       "Date                                                        \n",
       "2000-01-03                                            1.0   \n",
       "\n",
       "            (seasonal_trading, september_bear, SPY)  \\\n",
       "Date                                                  \n",
       "2000-01-03                                      0.0   \n",
       "\n",
       "            (seasonal_trading, tax_day_strategy, SPY)  \\\n",
       "Date                                                    \n",
       "2000-01-03                                        0.0   \n",
       "\n",
       "            (seasonal_trading, turn_around_tuesday_strategy, SPY)  \\\n",
       "Date                                                                \n",
       "2000-01-03                                                0.0       \n",
       "\n",
       "            SPY_ret_t_minus_1  \n",
       "Date                           \n",
       "2000-01-03          -0.009788  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_X_total.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa0d737-4782-4ed8-9fa1-d6c40a7c254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SPY\n",
       "Date                \n",
       "2000-01-03 -0.039106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_y_total.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c033c1-ae08-4434-a1ef-2f8578249408",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert orig_X_total.dropna().shape[0] == orig_X_total.shape[0]\n",
    "assert orig_y_total.dropna().shape[0] == orig_y_total.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875afeee-e714-42da-bd60-4faca3d4ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.058076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-14</th>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15</th>\n",
       "      <td>-0.004980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16</th>\n",
       "      <td>-0.005505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-20</th>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-21</th>\n",
       "      <td>0.020695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6072 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SPY\n",
       "Date                \n",
       "2000-01-03 -0.039106\n",
       "2000-01-04  0.001788\n",
       "2000-01-05 -0.016071\n",
       "2000-01-06  0.058076\n",
       "2000-01-07  0.003430\n",
       "...              ...\n",
       "2024-02-14  0.006900\n",
       "2024-02-15 -0.004980\n",
       "2024-02-16 -0.005505\n",
       "2024-02-20  0.000906\n",
       "2024-02-21  0.020695\n",
       "\n",
       "[6072 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_y_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060809a4-9cf3-4880-a151-bc56522795a5",
   "metadata": {},
   "source": [
    "## Create Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441990e-e411-417b-9a0d-c04523f31990",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e081a91-2d8f-4685-aa22-012f56bc7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a0311-96b5-4a56-9a08-ec8fe4f9e6c6",
   "metadata": {},
   "source": [
    "### Define `device` to use when training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788f0f18-8fd3-4240-b817-a3e52a379124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-23 13:45:16.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_device\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRunning on the CPU\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device() -> torch.device:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(\"Running on the GPU\")\n",
    "        n_gpu = 0 # different if you have more than 1\n",
    "        assert n_gpu <= (torch.cuda.device_count() - 1)\n",
    "        logger.info(f\"Using gpu={n_gpu} out of {torch.cuda.device_count()}\")\n",
    "        device = torch.device(f\"cuda:{n_gpu}\")\n",
    "    else:\n",
    "        logger.info(\"Running on the CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a867a3-f1ed-4a91-95b6-477d582971e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape = 10, Output Shape = 2\n",
      "X_sample.shape = torch.Size([10, 10]), y_sample.shape = torch.Size([10, 1])\n",
      "X_sample_translated.shape = torch.Size([6, 4, 10]), y_sample_translated.shape = torch.Size([6, 1])\n",
      "output.shape = torch.Size([6, 2])\n",
      "output = tensor([[0.6830, 0.3825],\n",
      "        [0.6940, 0.3872],\n",
      "        [0.6991, 0.3921],\n",
      "        [0.6903, 0.3831],\n",
      "        [0.6927, 0.3833],\n",
      "        [0.6895, 0.3904]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # Model Type: used to save model\n",
    "    MODEL_TYPE: str = \"rnn\"\n",
    "\n",
    "    # Sequences to use when creating prediction\n",
    "    DEFAULT_SEQUENCE_LENGTH: int = 5\n",
    "    # Step size to use when creating sequence\n",
    "    DEFAULT_STEP_SIZE: int = 1\n",
    "    \n",
    "    def __init__(self, input_shape: int, output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_shape: int = input_shape\n",
    "        self.output_shape: int = output_shape\n",
    "        \n",
    "        self.hidden_layers = 3\n",
    "        self.hidden_size = 10\n",
    "        \n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.input_shape, \n",
    "            hidden_size=self.hidden_size, \n",
    "            num_layers=self.hidden_layers, \n",
    "            batch_first=False,\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.hidden_size, 6)\n",
    "        self.fc2 = nn.Linear(6, 3)\n",
    "        self.fc3 = nn.Linear(3, self.output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Assuming x is (batch_size x seq_len x input_size)\n",
    "        assert x.size(2) == self.input_shape, f\"\"\"Provided `x` is not of shape \n",
    "            batch_size x seq_len x input_size: expected ? x ? x {self.input_shape} but received {x.shape}\"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        \n",
    "        # Set initial hidden state: (hidden layers x sequence length x hidden size)\n",
    "        h0 = torch.zeros(self.hidden_layers, seq_len, self.hidden_size)\n",
    "        \n",
    "        # Pass in x (sequence of values) and the initial hidden state (all zeros)\n",
    "        # Do not need hidden output so discard\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Output will be of shape batch_size x seq_len x hidden_size so get the last value in the sequence\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        # Apply layers after RNN\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        assert x.shape[-1] == self.output_shape\n",
    "\n",
    "        # Define Position in each asset\n",
    "        # output = F.tanh(x)\n",
    "        output = F.sigmoid(x)\n",
    "        # output = F.softmax(x, dim=1)\n",
    "        # output = F.tanh(x)\n",
    "        # output = torch.div(output.T, torch.sum(output, dim=1)).T\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def translate(X: torch.Tensor, y: torch.Tensor, sequence_length: int = DEFAULT_SEQUENCE_LENGTH, step_size: int = DEFAULT_STEP_SIZE,\n",
    "                 ) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        num_samples: int = X.shape[0]\n",
    "        num_variables: int = X.shape[1]\n",
    "        \n",
    "        # Create a new dataset with overlapping sequences\n",
    "        new_X = []\n",
    "        new_y = []\n",
    "        for i in range(sequence_length, num_samples, step_size):\n",
    "            # Fetch last `sequence_length` of X\n",
    "            new_X.append(X[(i - sequence_length):i])\n",
    "            # Fetch i-th value of y\n",
    "            new_y.append(y[i])\n",
    "    \n",
    "        # Convert lists to tensors\n",
    "        new_X = torch.stack(new_X)\n",
    "        new_y = torch.stack(new_y)\n",
    "            \n",
    "        return new_X, new_y\n",
    "\n",
    "\n",
    "def example():\n",
    "\n",
    "    # Define input and output sizes for neural network\n",
    "    INPUT_SHAPE = 10\n",
    "    OUTPUT_SHAPE = 2\n",
    "    print(f\"Input Shape = {INPUT_SHAPE}, Output Shape = {OUTPUT_SHAPE}\")\n",
    "\n",
    "    \n",
    "    # Generate example data\n",
    "    N_SAMPLES = 10\n",
    "    X_sample = torch.randn(N_SAMPLES, INPUT_SHAPE)\n",
    "    y_sample = torch.randn(N_SAMPLES, 1)\n",
    "    print(f\"{X_sample.shape = }, {y_sample.shape = }\")\n",
    "    \n",
    "    X_sample_translated, y_sample_translated = Net.translate(X=X_sample, y=y_sample, sequence_length=4, step_size=1)\n",
    "    print(f\"{X_sample_translated.shape = }, {y_sample_translated.shape = }\")\n",
    "\n",
    "    X_sample_translated = X_sample_translated.to(device=DEVICE)\n",
    "    y_sample_translated = y_sample_translated.to(device=DEVICE)\n",
    "\n",
    "    # Initiate Network\n",
    "    my_net = Net(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE).to(device=DEVICE)\n",
    "    output = my_net.forward(x=X_sample_translated)\n",
    "    print(f\"{output.shape = }\")\n",
    "    print(f\"{output = }\")\n",
    "    \n",
    "    return\n",
    "\n",
    "example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d2ded7-2fe6-4462-905d-d68eb3091a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn): RNN(10, 10, num_layers=3)\n",
       "  (fc1): Linear(in_features=10, out_features=6, bias=True)\n",
       "  (fc2): Linear(in_features=6, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net = Net(input_shape=10, output_shape=2).to(device=DEVICE)\n",
    "my_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2011f8-b5eb-4054-81f0-14dd7237ac2b",
   "metadata": {},
   "source": [
    "### Translate Data to Correct Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "17433c08-7f68-4003-ade1-598074c03915",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = False\n",
    "\n",
    "def convert_data_to_tensors(X: pd.DataFrame, y: pd.DataFrame) -> t.Tuple[torch.Tensor, torch.Tensor]:    \n",
    "    X_tensor = torch.Tensor(X.values) if isinstance(X, pd.DataFrame) else X\n",
    "    y_tensor = torch.Tensor(y.values) if isinstance(y, pd.DataFrame) else y\n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "def split_data(X: torch.Tensor, y: torch.Tensor) -> t.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    return train_test_split(X, y, train_size=0.7, shuffle=SHUFFLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "e1b323c7-69d5-49b9-8698-15c0b38b33d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([4246, 5, 9])\n",
      "y_train.shape = torch.Size([4246, 1])\n",
      "X_test.shape = torch.Size([1821, 5, 9])\n",
      "y_test.shape = torch.Size([1821, 1])\n"
     ]
    }
   ],
   "source": [
    "X_total, y_total = convert_data_to_tensors(X=orig_X_total, y=orig_y_total)\n",
    "X_total, y_total = Net.translate(X=X_total, y=y_total)\n",
    "X_train, X_test, y_train, y_test = split_data(X=X_total, y=y_total)\n",
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")\n",
    "print(f\"{y_test.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32143ca6-310b-4bfa-b8c7-e3f478456d6b",
   "metadata": {},
   "source": [
    "## Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "e2126532-96b7-4d6a-a447-c006f7e59477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    DEFAULT_PATIENCE: int = 5\n",
    "    DEFAULT_MIN_DELTA: int = 0\n",
    "    \n",
    "    def __init__(self, patience: int = DEFAULT_PATIENCE, min_delta: int = DEFAULT_MIN_DELTA, \n",
    "                 maximize: bool = False, min_periods: int = 0):\n",
    "\n",
    "        self.patience: int = patience\n",
    "        self.min_delta: int = min_delta\n",
    "        self.maximize: bool = maximize\n",
    "        self.min_periods: int = min_periods\n",
    "\n",
    "        # Benchmark Loss\n",
    "        self.best_loss: float = -np.inf if maximize else np.inf\n",
    "\n",
    "        # Number of Updates - used for min periods before applying early stopping\n",
    "        self.updates: int = 0\n",
    "        # Counter to count updates since last minimum\n",
    "        self.counter: int = 0\n",
    "        # Boolean to indicate whether to stop or continue training\n",
    "        self.early_stop: bool = False\n",
    "\n",
    "    def __call__(self, loss: float) -> None:\n",
    "\n",
    "        \"\"\" Updates state and sets `early_stop` to True when the loss has not improved by `min_loss` in `patience` updates. \"\"\"\n",
    "\n",
    "        self.updates += 1\n",
    "\n",
    "        if (((loss + self.min_delta) < self.best_loss) and not self.maximize) or (((loss - self.min_delta) > self.best_loss) and self.maximize):\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            return\n",
    "\n",
    "        if (((loss + self.min_delta) > self.best_loss) and not self.maximize) or (((loss - self.min_delta) < self.best_loss) and self.maximize):\n",
    "            self.counter += 1\n",
    "            if (self.counter >= self.patience) and (self.updates > self.min_periods):\n",
    "                self.early_stop = True\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900a8ae-0cec-4e0c-ba07-e9e31c5de16d",
   "metadata": {},
   "source": [
    "### Global Model Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "f638ae3a-8943-4794-a45f-7f70a7579181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    if output.shape[-1] != target.shape[-1]:\n",
    "        output = output.reshape(target.shape[0], target.shape[1])\n",
    "    \n",
    "    port_return = output * target\n",
    "    try:\n",
    "        port_return = torch.sum(port_return, dim=1)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    mean_return = torch.mean(port_return)\n",
    "    std_return = torch.std(port_return)\n",
    "    \n",
    "    sharpe = mean_return / (std_return + 1e-10)\n",
    "\n",
    "    num = torch.sum(torch.abs(output))\n",
    "    denom = output.shape[0]\n",
    "    multiplier = torch.sqrt(252 * num / denom)\n",
    "    \n",
    "    ann_sharpe = multiplier * sharpe\n",
    "    \n",
    "    return ann_sharpe\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.MSELoss()\n",
    "loss_function = my_loss\n",
    "\n",
    "MAXIMIZE_LOSS = True\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "TEST_BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "EARLY_STOPPING_MIN_DELTA = 0.0\n",
    "EARLY_STOPPING_MIN_PERIODS = 50\n",
    "\n",
    "assert BATCH_SIZE <= X_train.shape[0]\n",
    "assert TEST_BATCH_SIZE <= X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da590b-3297-4da2-be17-b2d55597cafe",
   "metadata": {},
   "source": [
    "### Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "2b0fd51b-7c05-4afe-88ed-9dc0488c4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prediction(net: Net, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    X = X.to(device=DEVICE)\n",
    "    y = y.to(device=DEVICE)\n",
    "\n",
    "    outputs = net(X)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def fwd_pass(net: Net, X: torch.Tensor, y: torch.Tensor, optimizer: torch.optim = None, do_train: bool = False):\n",
    "\n",
    "    acc = 0.15\n",
    "    \n",
    "    X = X.to(device=DEVICE)\n",
    "    y = y.to(device=DEVICE)\n",
    "\n",
    "    filtr = [(torch.sum(X[i, -1, :-y.shape[-1]]) != 0) for i in range(X.shape[0])]\n",
    "    # X, y = X[filtr], y[filtr]\n",
    "\n",
    "    if X.shape[0] < 1:\n",
    "        return 0, 0\n",
    "    \n",
    "    if do_train:\n",
    "        net.zero_grad()\n",
    "\n",
    "    outputs = net(X)\n",
    "    \n",
    "    matches = [int(i > 0) == int(j > 0) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True) / len(matches)\n",
    "    \n",
    "    loss = loss_function(outputs, y)\n",
    "\n",
    "    if do_train:\n",
    "        assert optimizer is not None, f\"Optimizer not provided in fwd_pass with training\"\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "def train(net: Net, store: bool = False):\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, maximize=MAXIMIZE_LOSS)\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=EARLY_STOPPING_PATIENCE, \n",
    "        min_delta=EARLY_STOPPING_MIN_DELTA, \n",
    "        maximize=MAXIMIZE_LOSS,\n",
    "        min_periods=EARLY_STOPPING_MIN_PERIODS,\n",
    "    )\n",
    "    \n",
    "    MODEL_NAME: str = f\"{net.MODEL_TYPE}-model-{int(time.time())}\"\n",
    "    \n",
    "    logger.info(f\"Training: {MODEL_NAME!r}\")\n",
    "\n",
    "    with open(f\"outputs/models/{net.MODEL_TYPE}-model-{MODEL_NAME}.log\", \"a\") as log:\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            \n",
    "            for i in tqdm(range(0, len(X_train), BATCH_SIZE)):\n",
    "\n",
    "                batch_X = X_train[i:(i + BATCH_SIZE)].to(device=DEVICE)\n",
    "                batch_y = y_train[i:(i + BATCH_SIZE)].to(device=DEVICE)\n",
    "\n",
    "                acc, loss = fwd_pass(net=net, X=batch_X, y=batch_y, optimizer=optimizer, do_train=True)\n",
    "            \n",
    "            # val_acc, val_loss = test(net=net, size=TEST_BATCH_SIZE)\n",
    "            acc, loss = evaluate(net=net, X=X_train, y=y_train)\n",
    "            val_acc, val_loss = evaluate(net=net, X=X_test, y=y_test)\n",
    "            if store:\n",
    "                log.write(f\"{MODEL_NAME},{time.time():.3f},{epoch},{acc:.4f},{loss:.4f},{val_acc:.4f},{val_loss:.4f}\\n\")\n",
    "            logger.info(f\"Epoch: {epoch} / {EPOCHS}, Loss: {loss}, Val Loss: {val_loss}, Accuracy: {acc}, Val Accuracy: {val_acc}\")\n",
    "\n",
    "            # early stopping\n",
    "            early_stopping(loss)\n",
    "            if early_stopping.early_stop:\n",
    "                val_acc, val_loss = test(net=net, size=None)\n",
    "                logger.info(f\"Early Stopping reached @ {epoch = }! Best Loss: {early_stopping.best_loss}, Loss: {loss},\" +\\\n",
    "                            f\"Val Loss: {val_loss}, Accuracy: {acc}, Val Accuracy: {val_acc}\")\n",
    "                break\n",
    "\n",
    "    if store:\n",
    "        torch.save(net.state_dict(), f\"outputs/models/{net.MODEL_TYPE}-model-{MODEL_NAME}-state.dict\")\n",
    "        shutil.copy(f\"outputs/models/{net.MODEL_TYPE}-model-{MODEL_NAME}.log\", f\"outputs/models/{net.MODEL_TYPE}-model-latest.log\")\n",
    "        shutil.copy(f\"outputs/models/{net.MODEL_TYPE}-model-{MODEL_NAME}-state.dict\", f\"outputs/models/{net.MODEL_TYPE}-model-latest-state.dict\")\n",
    "    else:\n",
    "        os.remove(f\"outputs/models/{net.MODEL_TYPE}-model-{MODEL_NAME}.log\")\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "def test(net: Net, size: int = None) -> t.Tuple[float, torch.Tensor]:\n",
    "\n",
    "    if size is None:\n",
    "        X, y = X_test, y_test\n",
    "    else:\n",
    "        # Get random split of test data of size `size`\n",
    "        random_start = np.random.randint(X_test.shape[0] - size)\n",
    "        X, y = X_test[random_start:(random_start + size)], y_test[random_start:(random_start + size)]\n",
    "\n",
    "    filtr = [(torch.sum(X[i, -1, :-1]) != 0) for i in range(X.shape[0])]\n",
    "    X, y = X[filtr], y[filtr]\n",
    "    \n",
    "    return evaluate(net=net, X=X, y=y)\n",
    "\n",
    "\n",
    "def evaluate(net: Net, X: torch.Tensor, y: torch.Tensor) -> t.Tuple[float, torch.Tensor]:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acc, loss = fwd_pass(net=net, X=X, y=y, do_train=False)\n",
    "\n",
    "    return acc, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25dcb6-6cfe-4a0d-a77c-99b30df33b29",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "bf1f9b77-f610-4fc6-a236-411aed08991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: 9, Output Shape: 1\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = X_train.shape[-1]\n",
    "OUTPUT_SHAPE = y_train.shape[-1]\n",
    "\n",
    "print(f\"Input Shape: {INPUT_SHAPE}, Output Shape: {OUTPUT_SHAPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "f84d4814-d13d-4632-8ccd-a37cd1d03bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-22 21:37:38.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mTraining: 'rnn-model-1708637858'\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.54it/s]\n",
      "\u001b[32m2024-02-22 21:37:40.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 0 / 1000, Loss: 0.3080836832523346, Val Loss: 0.7783706188201904, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.71it/s]\n",
      "\u001b[32m2024-02-22 21:37:43.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 1 / 1000, Loss: 0.31330785155296326, Val Loss: 0.7931838631629944, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 42.36it/s]\n",
      "\u001b[32m2024-02-22 21:37:45.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 2 / 1000, Loss: 0.3143881559371948, Val Loss: 0.7961813807487488, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.91it/s]\n",
      "\u001b[32m2024-02-22 21:37:48.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 3 / 1000, Loss: 0.3148132562637329, Val Loss: 0.797377347946167, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.67it/s]\n",
      "\u001b[32m2024-02-22 21:37:51.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 4 / 1000, Loss: 0.3150310218334198, Val Loss: 0.7979931831359863, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.76it/s]\n",
      "\u001b[32m2024-02-22 21:37:54.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 5 / 1000, Loss: 0.3151603639125824, Val Loss: 0.7983596324920654, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.47it/s]\n",
      "\u001b[32m2024-02-22 21:37:56.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 6 / 1000, Loss: 0.31524476408958435, Val Loss: 0.7985986471176147, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.09it/s]\n",
      "\u001b[32m2024-02-22 21:37:59.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 7 / 1000, Loss: 0.31530338525772095, Val Loss: 0.7987650036811829, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.67it/s]\n",
      "\u001b[32m2024-02-22 21:38:01.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 8 / 1000, Loss: 0.3153461813926697, Val Loss: 0.798886239528656, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.74it/s]\n",
      "\u001b[32m2024-02-22 21:38:04.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 9 / 1000, Loss: 0.3153786361217499, Val Loss: 0.7989776730537415, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.99it/s]\n",
      "\u001b[32m2024-02-22 21:38:07.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 10 / 1000, Loss: 0.3154037296772003, Val Loss: 0.7990488409996033, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.43it/s]\n",
      "\u001b[32m2024-02-22 21:38:09.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 11 / 1000, Loss: 0.3154236972332001, Val Loss: 0.7991051077842712, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 43.22it/s]\n",
      "\u001b[32m2024-02-22 21:38:11.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 12 / 1000, Loss: 0.3154400587081909, Val Loss: 0.7991511821746826, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.56it/s]\n",
      "\u001b[32m2024-02-22 21:38:14.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 13 / 1000, Loss: 0.3154533803462982, Val Loss: 0.7991888523101807, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 42.37it/s]\n",
      "\u001b[32m2024-02-22 21:38:16.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 14 / 1000, Loss: 0.3154646158218384, Val Loss: 0.7992202639579773, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.15it/s]\n",
      "\u001b[32m2024-02-22 21:38:19.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 15 / 1000, Loss: 0.3154740631580353, Val Loss: 0.7992469072341919, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.36it/s]\n",
      "\u001b[32m2024-02-22 21:38:22.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 16 / 1000, Loss: 0.3154821991920471, Val Loss: 0.7992694973945618, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.46it/s]\n",
      "\u001b[32m2024-02-22 21:38:24.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 17 / 1000, Loss: 0.31548911333084106, Val Loss: 0.7992889881134033, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.55it/s]\n",
      "\u001b[32m2024-02-22 21:38:27.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 18 / 1000, Loss: 0.3154951333999634, Val Loss: 0.7993061542510986, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 42.83it/s]\n",
      "\u001b[32m2024-02-22 21:38:29.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 19 / 1000, Loss: 0.3155004680156708, Val Loss: 0.7993208169937134, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 42.74it/s]\n",
      "\u001b[32m2024-02-22 21:38:31.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 20 / 1000, Loss: 0.31550511717796326, Val Loss: 0.7993337512016296, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.85it/s]\n",
      "\u001b[32m2024-02-22 21:38:34.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 21 / 1000, Loss: 0.3155091404914856, Val Loss: 0.7993454337120056, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 42.32it/s]\n",
      "\u001b[32m2024-02-22 21:38:37.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 22 / 1000, Loss: 0.3155129551887512, Val Loss: 0.7993557453155518, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.89it/s]\n",
      "\u001b[32m2024-02-22 21:38:39.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 23 / 1000, Loss: 0.3155162036418915, Val Loss: 0.7993650436401367, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.87it/s]\n",
      "\u001b[32m2024-02-22 21:38:42.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 24 / 1000, Loss: 0.31551918387413025, Val Loss: 0.7993731498718262, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.86it/s]\n",
      "\u001b[32m2024-02-22 21:38:44.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 25 / 1000, Loss: 0.31552180647850037, Val Loss: 0.7993806004524231, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.73it/s]\n",
      "\u001b[32m2024-02-22 21:38:47.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 26 / 1000, Loss: 0.31552428007125854, Val Loss: 0.7993873953819275, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.91it/s]\n",
      "\u001b[32m2024-02-22 21:38:49.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 27 / 1000, Loss: 0.31552648544311523, Val Loss: 0.7993935942649841, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.39it/s]\n",
      "\u001b[32m2024-02-22 21:38:52.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 28 / 1000, Loss: 0.31552854180336, Val Loss: 0.7993991374969482, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.35it/s]\n",
      "\u001b[32m2024-02-22 21:38:55.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 29 / 1000, Loss: 0.3155304193496704, Val Loss: 0.7994042634963989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.81it/s]\n",
      "\u001b[32m2024-02-22 21:38:57.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 30 / 1000, Loss: 0.3155320882797241, Val Loss: 0.7994089722633362, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.49it/s]\n",
      "\u001b[32m2024-02-22 21:39:00.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 31 / 1000, Loss: 0.3155335485935211, Val Loss: 0.7994132041931152, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.30it/s]\n",
      "\u001b[32m2024-02-22 21:39:03.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 32 / 1000, Loss: 0.3155349791049957, Val Loss: 0.79941725730896, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.77it/s]\n",
      "\u001b[32m2024-02-22 21:39:06.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 33 / 1000, Loss: 0.31553637981414795, Val Loss: 0.7994208931922913, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.08it/s]\n",
      "\u001b[32m2024-02-22 21:39:09.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 34 / 1000, Loss: 0.3155376613140106, Val Loss: 0.7994242310523987, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.83it/s]\n",
      "\u001b[32m2024-02-22 21:39:11.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 35 / 1000, Loss: 0.31553879380226135, Val Loss: 0.7994274497032166, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.32it/s]\n",
      "\u001b[32m2024-02-22 21:39:14.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 36 / 1000, Loss: 0.31553977727890015, Val Loss: 0.799430251121521, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.66it/s]\n",
      "\u001b[32m2024-02-22 21:39:16.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 37 / 1000, Loss: 0.31554073095321655, Val Loss: 0.7994330525398254, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.61it/s]\n",
      "\u001b[32m2024-02-22 21:39:19.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 38 / 1000, Loss: 0.31554168462753296, Val Loss: 0.7994356155395508, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.98it/s]\n",
      "\u001b[32m2024-02-22 21:39:21.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 39 / 1000, Loss: 0.31554263830184937, Val Loss: 0.7994380593299866, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.96it/s]\n",
      "\u001b[32m2024-02-22 21:39:24.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 40 / 1000, Loss: 0.31554335355758667, Val Loss: 0.7994402647018433, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.75it/s]\n",
      "\u001b[32m2024-02-22 21:39:26.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 41 / 1000, Loss: 0.31554409861564636, Val Loss: 0.7994423508644104, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.40it/s]\n",
      "\u001b[32m2024-02-22 21:39:29.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 42 / 1000, Loss: 0.31554487347602844, Val Loss: 0.7994440793991089, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.72it/s]\n",
      "\u001b[32m2024-02-22 21:39:31.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 43 / 1000, Loss: 0.3155454695224762, Val Loss: 0.7994460463523865, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.18it/s]\n",
      "\u001b[32m2024-02-22 21:39:34.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 44 / 1000, Loss: 0.31554606556892395, Val Loss: 0.7994478344917297, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.91it/s]\n",
      "\u001b[32m2024-02-22 21:39:36.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 45 / 1000, Loss: 0.3155466914176941, Val Loss: 0.7994492650032043, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.14it/s]\n",
      "\u001b[32m2024-02-22 21:39:38.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 46 / 1000, Loss: 0.31554731726646423, Val Loss: 0.7994509339332581, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.86it/s]\n",
      "\u001b[32m2024-02-22 21:39:41.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 47 / 1000, Loss: 0.3155477046966553, Val Loss: 0.7994523048400879, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.37it/s]\n",
      "\u001b[32m2024-02-22 21:39:44.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 48 / 1000, Loss: 0.31554821133613586, Val Loss: 0.799453616142273, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.99it/s]\n",
      "\u001b[32m2024-02-22 21:39:47.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 49 / 1000, Loss: 0.31554868817329407, Val Loss: 0.7994549870491028, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.09it/s]\n",
      "\u001b[32m2024-02-22 21:39:50.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 50 / 1000, Loss: 0.31554916501045227, Val Loss: 0.7994561195373535, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.73it/s]\n",
      "\u001b[32m2024-02-22 21:39:53.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 51 / 1000, Loss: 0.3155496418476105, Val Loss: 0.799457311630249, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.96it/s]\n",
      "\u001b[32m2024-02-22 21:39:55.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 52 / 1000, Loss: 0.3155499994754791, Val Loss: 0.7994584441184998, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.12it/s]\n",
      "\u001b[32m2024-02-22 21:39:58.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 53 / 1000, Loss: 0.31555038690567017, Val Loss: 0.7994595766067505, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.85it/s]\n",
      "\u001b[32m2024-02-22 21:40:00.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 54 / 1000, Loss: 0.31555068492889404, Val Loss: 0.7994604110717773, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.94it/s]\n",
      "\u001b[32m2024-02-22 21:40:03.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 55 / 1000, Loss: 0.31555110216140747, Val Loss: 0.7994613647460938, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.22it/s]\n",
      "\u001b[32m2024-02-22 21:40:06.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 56 / 1000, Loss: 0.31555137038230896, Val Loss: 0.7994623780250549, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.02it/s]\n",
      "\u001b[32m2024-02-22 21:40:08.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 57 / 1000, Loss: 0.3155517280101776, Val Loss: 0.799463152885437, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 40.14it/s]\n",
      "\u001b[32m2024-02-22 21:40:11.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 58 / 1000, Loss: 0.3155519664287567, Val Loss: 0.7994638681411743, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 44.57it/s]\n",
      "\u001b[32m2024-02-22 21:40:13.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 59 / 1000, Loss: 0.3155522048473358, Val Loss: 0.7994645833969116, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.82it/s]\n",
      "\u001b[32m2024-02-22 21:40:15.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 60 / 1000, Loss: 0.31555256247520447, Val Loss: 0.7994653582572937, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 45.28it/s]\n",
      "\u001b[32m2024-02-22 21:40:18.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 61 / 1000, Loss: 0.31555280089378357, Val Loss: 0.7994660139083862, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 43.42it/s]\n",
      "\u001b[32m2024-02-22 21:40:20.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 62 / 1000, Loss: 0.3155529201030731, Val Loss: 0.799466609954834, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 41.58it/s]\n",
      "\u001b[32m2024-02-22 21:40:22.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 63 / 1000, Loss: 0.315553218126297, Val Loss: 0.7994673252105713, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.96it/s]\n",
      "\u001b[32m2024-02-22 21:40:25.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 64 / 1000, Loss: 0.3155534863471985, Val Loss: 0.7994679808616638, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.29it/s]\n",
      "\u001b[32m2024-02-22 21:40:28.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 65 / 1000, Loss: 0.3155536353588104, Val Loss: 0.7994685173034668, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.22it/s]\n",
      "\u001b[32m2024-02-22 21:40:31.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 66 / 1000, Loss: 0.3155538737773895, Val Loss: 0.7994691133499146, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.73it/s]\n",
      "\u001b[32m2024-02-22 21:40:35.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 67 / 1000, Loss: 0.31555405259132385, Val Loss: 0.799469530582428, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.45it/s]\n",
      "\u001b[32m2024-02-22 21:40:38.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 68 / 1000, Loss: 0.3155542314052582, Val Loss: 0.7994701266288757, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.20it/s]\n",
      "\u001b[32m2024-02-22 21:40:41.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 69 / 1000, Loss: 0.3155544698238373, Val Loss: 0.7994704842567444, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.15it/s]\n",
      "\u001b[32m2024-02-22 21:40:43.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 70 / 1000, Loss: 0.3155546188354492, Val Loss: 0.7994710803031921, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 28.50it/s]\n",
      "\u001b[32m2024-02-22 21:40:47.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 71 / 1000, Loss: 0.31555479764938354, Val Loss: 0.799471378326416, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 26.36it/s]\n",
      "\u001b[32m2024-02-22 21:40:50.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 72 / 1000, Loss: 0.3155549466609955, Val Loss: 0.7994717955589294, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 30.45it/s]\n",
      "\u001b[32m2024-02-22 21:40:54.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 73 / 1000, Loss: 0.31555500626564026, Val Loss: 0.7994722127914429, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.25it/s]\n",
      "\u001b[32m2024-02-22 21:40:57.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 74 / 1000, Loss: 0.3155551552772522, Val Loss: 0.7994726896286011, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.65it/s]\n",
      "\u001b[32m2024-02-22 21:41:00.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 75 / 1000, Loss: 0.3155553340911865, Val Loss: 0.7994731068611145, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.97it/s]\n",
      "\u001b[32m2024-02-22 21:41:03.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 76 / 1000, Loss: 0.31555548310279846, Val Loss: 0.7994734644889832, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.71it/s]\n",
      "\u001b[32m2024-02-22 21:41:05.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 77 / 1000, Loss: 0.3155556619167328, Val Loss: 0.799473762512207, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.58it/s]\n",
      "\u001b[32m2024-02-22 21:41:09.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 78 / 1000, Loss: 0.31555572152137756, Val Loss: 0.7994741201400757, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.08it/s]\n",
      "\u001b[32m2024-02-22 21:41:12.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 79 / 1000, Loss: 0.3155558407306671, Val Loss: 0.79947429895401, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.31it/s]\n",
      "\u001b[32m2024-02-22 21:41:15.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 80 / 1000, Loss: 0.3155559003353119, Val Loss: 0.7994745969772339, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.88it/s]\n",
      "\u001b[32m2024-02-22 21:41:17.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 81 / 1000, Loss: 0.3155561089515686, Val Loss: 0.799474835395813, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.53it/s]\n",
      "\u001b[32m2024-02-22 21:41:20.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 82 / 1000, Loss: 0.315556138753891, Val Loss: 0.7994752526283264, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.69it/s]\n",
      "\u001b[32m2024-02-22 21:41:23.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 83 / 1000, Loss: 0.31555622816085815, Val Loss: 0.7994756102561951, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.98it/s]\n",
      "\u001b[32m2024-02-22 21:41:26.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 84 / 1000, Loss: 0.3155563473701477, Val Loss: 0.7994757890701294, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.19it/s]\n",
      "\u001b[32m2024-02-22 21:41:29.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 85 / 1000, Loss: 0.3155563771724701, Val Loss: 0.7994759678840637, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.83it/s]\n",
      "\u001b[32m2024-02-22 21:41:32.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 86 / 1000, Loss: 0.31555643677711487, Val Loss: 0.799476146697998, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.89it/s]\n",
      "\u001b[32m2024-02-22 21:41:34.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 87 / 1000, Loss: 0.3155566155910492, Val Loss: 0.7994764447212219, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.14it/s]\n",
      "\u001b[32m2024-02-22 21:41:37.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 88 / 1000, Loss: 0.3155566453933716, Val Loss: 0.7994765043258667, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.28it/s]\n",
      "\u001b[32m2024-02-22 21:41:40.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 89 / 1000, Loss: 0.3155568242073059, Val Loss: 0.7994769215583801, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.91it/s]\n",
      "\u001b[32m2024-02-22 21:41:43.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 90 / 1000, Loss: 0.3155568540096283, Val Loss: 0.7994771003723145, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.73it/s]\n",
      "\u001b[32m2024-02-22 21:41:46.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 91 / 1000, Loss: 0.3155568838119507, Val Loss: 0.7994772791862488, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.04it/s]\n",
      "\u001b[32m2024-02-22 21:41:48.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 92 / 1000, Loss: 0.31555691361427307, Val Loss: 0.7994775176048279, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.97it/s]\n",
      "\u001b[32m2024-02-22 21:41:52.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 93 / 1000, Loss: 0.3155570328235626, Val Loss: 0.7994776964187622, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.85it/s]\n",
      "\u001b[32m2024-02-22 21:41:55.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 94 / 1000, Loss: 0.315557062625885, Val Loss: 0.7994778752326965, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.25it/s]\n",
      "\u001b[32m2024-02-22 21:41:57.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 95 / 1000, Loss: 0.31555721163749695, Val Loss: 0.7994779944419861, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.02it/s]\n",
      "\u001b[32m2024-02-22 21:42:00.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 96 / 1000, Loss: 0.31555724143981934, Val Loss: 0.7994781136512756, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.46it/s]\n",
      "\u001b[32m2024-02-22 21:42:03.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 97 / 1000, Loss: 0.3155573010444641, Val Loss: 0.7994782328605652, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.96it/s]\n",
      "\u001b[32m2024-02-22 21:42:06.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 98 / 1000, Loss: 0.3155573010444641, Val Loss: 0.7994783520698547, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.43it/s]\n",
      "\u001b[32m2024-02-22 21:42:09.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 99 / 1000, Loss: 0.3155573606491089, Val Loss: 0.7994785904884338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.04it/s]\n",
      "\u001b[32m2024-02-22 21:42:12.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 100 / 1000, Loss: 0.31555742025375366, Val Loss: 0.7994786500930786, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.94it/s]\n",
      "\u001b[32m2024-02-22 21:42:16.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 101 / 1000, Loss: 0.3155575692653656, Val Loss: 0.7994787693023682, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.87it/s]\n",
      "\u001b[32m2024-02-22 21:42:18.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 102 / 1000, Loss: 0.3155575394630432, Val Loss: 0.7994789481163025, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.52it/s]\n",
      "\u001b[32m2024-02-22 21:42:21.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 103 / 1000, Loss: 0.315557599067688, Val Loss: 0.7994791865348816, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.88it/s]\n",
      "\u001b[32m2024-02-22 21:42:24.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 104 / 1000, Loss: 0.31555771827697754, Val Loss: 0.7994791865348816, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.24it/s]\n",
      "\u001b[32m2024-02-22 21:42:27.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 105 / 1000, Loss: 0.31555771827697754, Val Loss: 0.7994793653488159, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.33it/s]\n",
      "\u001b[32m2024-02-22 21:42:29.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 106 / 1000, Loss: 0.3155577778816223, Val Loss: 0.799479603767395, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 27.79it/s]\n",
      "\u001b[32m2024-02-22 21:42:33.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 107 / 1000, Loss: 0.3155578076839447, Val Loss: 0.799479603767395, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.72it/s]\n",
      "\u001b[32m2024-02-22 21:42:35.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 108 / 1000, Loss: 0.3155577778816223, Val Loss: 0.7994797825813293, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.59it/s]\n",
      "\u001b[32m2024-02-22 21:42:38.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 109 / 1000, Loss: 0.3155578076839447, Val Loss: 0.7994797825813293, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.34it/s]\n",
      "\u001b[32m2024-02-22 21:42:41.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 110 / 1000, Loss: 0.31555798649787903, Val Loss: 0.7994800209999084, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.97it/s]\n",
      "\u001b[32m2024-02-22 21:42:44.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 111 / 1000, Loss: 0.31555789709091187, Val Loss: 0.7994800806045532, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.73it/s]\n",
      "\u001b[32m2024-02-22 21:42:47.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 112 / 1000, Loss: 0.31555789709091187, Val Loss: 0.7994800806045532, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.32it/s]\n",
      "\u001b[32m2024-02-22 21:42:50.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 113 / 1000, Loss: 0.3155580461025238, Val Loss: 0.799480140209198, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.99it/s]\n",
      "\u001b[32m2024-02-22 21:42:53.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 114 / 1000, Loss: 0.3155580163002014, Val Loss: 0.7994801998138428, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.18it/s]\n",
      "\u001b[32m2024-02-22 21:42:56.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 115 / 1000, Loss: 0.3155580163002014, Val Loss: 0.7994803190231323, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.77it/s]\n",
      "\u001b[32m2024-02-22 21:42:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 116 / 1000, Loss: 0.3155580461025238, Val Loss: 0.7994803786277771, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.81it/s]\n",
      "\u001b[32m2024-02-22 21:43:01.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 117 / 1000, Loss: 0.3155580759048462, Val Loss: 0.7994804382324219, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.47it/s]\n",
      "\u001b[32m2024-02-22 21:43:04.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 118 / 1000, Loss: 0.31555822491645813, Val Loss: 0.7994804382324219, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.38it/s]\n",
      "\u001b[32m2024-02-22 21:43:07.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 119 / 1000, Loss: 0.31555819511413574, Val Loss: 0.799480676651001, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.18it/s]\n",
      "\u001b[32m2024-02-22 21:43:10.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 120 / 1000, Loss: 0.31555816531181335, Val Loss: 0.7994807958602905, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.89it/s]\n",
      "\u001b[32m2024-02-22 21:43:13.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 121 / 1000, Loss: 0.31555816531181335, Val Loss: 0.7994807362556458, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.40it/s]\n",
      "\u001b[32m2024-02-22 21:43:15.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 122 / 1000, Loss: 0.31555819511413574, Val Loss: 0.7994807958602905, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.74it/s]\n",
      "\u001b[32m2024-02-22 21:43:18.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 123 / 1000, Loss: 0.3155582547187805, Val Loss: 0.7994808554649353, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.01it/s]\n",
      "\u001b[32m2024-02-22 21:43:21.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 124 / 1000, Loss: 0.31555840373039246, Val Loss: 0.7994810342788696, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.85it/s]\n",
      "\u001b[32m2024-02-22 21:43:24.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 125 / 1000, Loss: 0.3155583441257477, Val Loss: 0.7994810938835144, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.50it/s]\n",
      "\u001b[32m2024-02-22 21:43:27.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 126 / 1000, Loss: 0.3155582845211029, Val Loss: 0.7994810938835144, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.73it/s]\n",
      "\u001b[32m2024-02-22 21:43:29.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 127 / 1000, Loss: 0.3155583143234253, Val Loss: 0.7994810938835144, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.53it/s]\n",
      "\u001b[32m2024-02-22 21:43:32.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 128 / 1000, Loss: 0.3155582845211029, Val Loss: 0.7994810938835144, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.08it/s]\n",
      "\u001b[32m2024-02-22 21:43:35.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 129 / 1000, Loss: 0.3155583143234253, Val Loss: 0.7994810938835144, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.67it/s]\n",
      "\u001b[32m2024-02-22 21:43:38.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 130 / 1000, Loss: 0.3155582547187805, Val Loss: 0.7994811534881592, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.89it/s]\n",
      "\u001b[32m2024-02-22 21:43:41.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 131 / 1000, Loss: 0.3155582845211029, Val Loss: 0.7994811534881592, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.65it/s]\n",
      "\u001b[32m2024-02-22 21:43:44.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 132 / 1000, Loss: 0.31555840373039246, Val Loss: 0.7994813919067383, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.35it/s]\n",
      "\u001b[32m2024-02-22 21:43:46.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 133 / 1000, Loss: 0.31555843353271484, Val Loss: 0.7994813919067383, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.91it/s]\n",
      "\u001b[32m2024-02-22 21:43:49.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 134 / 1000, Loss: 0.31555843353271484, Val Loss: 0.7994813919067383, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.16it/s]\n",
      "\u001b[32m2024-02-22 21:43:52.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 135 / 1000, Loss: 0.31555840373039246, Val Loss: 0.7994815111160278, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.35it/s]\n",
      "\u001b[32m2024-02-22 21:43:55.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 136 / 1000, Loss: 0.3155584931373596, Val Loss: 0.7994815707206726, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.99it/s]\n",
      "\u001b[32m2024-02-22 21:43:58.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 137 / 1000, Loss: 0.31555843353271484, Val Loss: 0.7994815111160278, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.21it/s]\n",
      "\u001b[32m2024-02-22 21:44:00.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 138 / 1000, Loss: 0.31555837392807007, Val Loss: 0.7994815111160278, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.55it/s]\n",
      "\u001b[32m2024-02-22 21:44:03.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 139 / 1000, Loss: 0.31555843353271484, Val Loss: 0.7994815111160278, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.50it/s]\n",
      "\u001b[32m2024-02-22 21:44:06.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 140 / 1000, Loss: 0.315558522939682, Val Loss: 0.7994816303253174, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.48it/s]\n",
      "\u001b[32m2024-02-22 21:44:09.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 141 / 1000, Loss: 0.31555861234664917, Val Loss: 0.7994818687438965, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 26.99it/s]\n",
      "\u001b[32m2024-02-22 21:44:12.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 142 / 1000, Loss: 0.3155585527420044, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.33it/s]\n",
      "\u001b[32m2024-02-22 21:44:15.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 143 / 1000, Loss: 0.3155585527420044, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.57it/s]\n",
      "\u001b[32m2024-02-22 21:44:18.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 144 / 1000, Loss: 0.3155585527420044, Val Loss: 0.7994817495346069, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.00it/s]\n",
      "\u001b[32m2024-02-22 21:44:21.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 145 / 1000, Loss: 0.315558522939682, Val Loss: 0.7994818687438965, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.98it/s]\n",
      "\u001b[32m2024-02-22 21:44:24.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 146 / 1000, Loss: 0.315558522939682, Val Loss: 0.7994818687438965, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.16it/s]\n",
      "\u001b[32m2024-02-22 21:44:27.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 147 / 1000, Loss: 0.31555861234664917, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.26it/s]\n",
      "\u001b[32m2024-02-22 21:44:30.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 148 / 1000, Loss: 0.31555861234664917, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.18it/s]\n",
      "\u001b[32m2024-02-22 21:44:32.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 149 / 1000, Loss: 0.31555864214897156, Val Loss: 0.7994819283485413, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.58it/s]\n",
      "\u001b[32m2024-02-22 21:44:35.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 150 / 1000, Loss: 0.31555864214897156, Val Loss: 0.7994819283485413, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.39it/s]\n",
      "\u001b[32m2024-02-22 21:44:38.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 151 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.89it/s]\n",
      "\u001b[32m2024-02-22 21:44:42.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 152 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994818091392517, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.52it/s]\n",
      "\u001b[32m2024-02-22 21:44:44.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 153 / 1000, Loss: 0.31555861234664917, Val Loss: 0.7994820475578308, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.76it/s]\n",
      "\u001b[32m2024-02-22 21:44:47.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 154 / 1000, Loss: 0.31555861234664917, Val Loss: 0.7994820475578308, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.76it/s]\n",
      "\u001b[32m2024-02-22 21:44:50.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 155 / 1000, Loss: 0.3155585825443268, Val Loss: 0.799481987953186, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.84it/s]\n",
      "\u001b[32m2024-02-22 21:44:53.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 156 / 1000, Loss: 0.3155585825443268, Val Loss: 0.799481987953186, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.73it/s]\n",
      "\u001b[32m2024-02-22 21:44:56.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 157 / 1000, Loss: 0.3155585825443268, Val Loss: 0.799481987953186, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.77it/s]\n",
      "\u001b[32m2024-02-22 21:44:59.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 158 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.67it/s]\n",
      "\u001b[32m2024-02-22 21:45:01.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 159 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.80it/s]\n",
      "\u001b[32m2024-02-22 21:45:04.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 160 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994822263717651, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.31it/s]\n",
      "\u001b[32m2024-02-22 21:45:07.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 161 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 23.25it/s]\n",
      "\u001b[32m2024-02-22 21:45:11.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 162 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.12it/s]\n",
      "\u001b[32m2024-02-22 21:45:14.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 163 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994822263717651, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.30it/s]\n",
      "\u001b[32m2024-02-22 21:45:17.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 164 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994822263717651, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 28.82it/s]\n",
      "\u001b[32m2024-02-22 21:45:21.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 165 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994822263717651, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 33.42it/s]\n",
      "\u001b[32m2024-02-22 21:45:24.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 166 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994822263717651, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 30.21it/s]\n",
      "\u001b[32m2024-02-22 21:45:27.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 167 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.71it/s]\n",
      "\u001b[32m2024-02-22 21:45:30.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 168 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.25it/s]\n",
      "\u001b[32m2024-02-22 21:45:33.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 169 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.46it/s]\n",
      "\u001b[32m2024-02-22 21:45:36.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 170 / 1000, Loss: 0.3155587911605835, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.46it/s]\n",
      "\u001b[32m2024-02-22 21:45:39.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 171 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.21it/s]\n",
      "\u001b[32m2024-02-22 21:45:42.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 172 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.30it/s]\n",
      "\u001b[32m2024-02-22 21:45:45.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 173 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.09it/s]\n",
      "\u001b[32m2024-02-22 21:45:48.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 174 / 1000, Loss: 0.31555870175361633, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 28.21it/s]\n",
      "\u001b[32m2024-02-22 21:45:52.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 175 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 27.42it/s]\n",
      "\u001b[32m2024-02-22 21:45:55.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 176 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.20it/s]\n",
      "\u001b[32m2024-02-22 21:45:58.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 177 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 44.41it/s]\n",
      "\u001b[32m2024-02-22 21:46:00.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 178 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.89it/s]\n",
      "\u001b[32m2024-02-22 21:46:03.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 179 / 1000, Loss: 0.3155587315559387, Val Loss: 0.7994821667671204, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.09it/s]\n",
      "\u001b[32m2024-02-22 21:46:05.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 180 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.82it/s]\n",
      "\u001b[32m2024-02-22 21:46:08.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 181 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 39.52it/s]\n",
      "\u001b[32m2024-02-22 21:46:11.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 182 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 38.18it/s]\n",
      "\u001b[32m2024-02-22 21:46:13.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 183 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.20it/s]\n",
      "\u001b[32m2024-02-22 21:46:17.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 184 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 26.67it/s]\n",
      "\u001b[32m2024-02-22 21:46:21.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 185 / 1000, Loss: 0.3155587613582611, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.81it/s]\n",
      "\u001b[32m2024-02-22 21:46:24.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 186 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 21.99it/s]\n",
      "\u001b[32m2024-02-22 21:46:30.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 187 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:05<00:00, 13.34it/s]\n",
      "\u001b[32m2024-02-22 21:46:37.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 188 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.72it/s]\n",
      "\u001b[32m2024-02-22 21:46:46.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 189 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  9.17it/s]\n",
      "\u001b[32m2024-02-22 21:46:59.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 190 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:16<00:00,  4.12it/s]\n",
      "\u001b[32m2024-02-22 21:47:22.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 191 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:23<00:00,  2.87it/s]\n",
      "\u001b[32m2024-02-22 21:47:52.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 192 / 1000, Loss: 0.3155588209629059, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:11<00:00,  5.71it/s]\n",
      "\u001b[32m2024-02-22 21:48:10.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 193 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994826436042786, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:06<00:00, 10.48it/s]\n",
      "\u001b[32m2024-02-22 21:48:19.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 194 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 14.85it/s]\n",
      "\u001b[32m2024-02-22 21:48:26.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 195 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  7.40it/s]\n",
      "\u001b[32m2024-02-22 21:48:41.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 196 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.98it/s]\n",
      "\u001b[32m2024-02-22 21:48:54.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 197 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.88it/s]\n",
      "\u001b[32m2024-02-22 21:49:06.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 198 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:05<00:00, 11.82it/s]\n",
      "\u001b[32m2024-02-22 21:49:14.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 199 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 14.97it/s]\n",
      "\u001b[32m2024-02-22 21:49:21.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 200 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 29.94it/s]\n",
      "\u001b[32m2024-02-22 21:49:24.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 201 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 28.17it/s]\n",
      "\u001b[32m2024-02-22 21:49:28.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 202 / 1000, Loss: 0.31555885076522827, Val Loss: 0.799482524394989, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 29.59it/s]\n",
      "\u001b[32m2024-02-22 21:49:33.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 203 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:05<00:00, 12.71it/s]\n",
      "\u001b[32m2024-02-22 21:49:41.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 204 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:04<00:00, 13.44it/s]\n",
      "\u001b[32m2024-02-22 21:49:47.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 205 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 26.66it/s]\n",
      "\u001b[32m2024-02-22 21:49:51.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 206 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 25.32it/s]\n",
      "\u001b[32m2024-02-22 21:49:55.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 207 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 25.22it/s]\n",
      "\u001b[32m2024-02-22 21:49:59.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 208 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.84it/s]\n",
      "\u001b[32m2024-02-22 21:50:02.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 209 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.94it/s]\n",
      "\u001b[32m2024-02-22 21:50:05.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 210 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.27it/s]\n",
      "\u001b[32m2024-02-22 21:50:08.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 211 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 35.74it/s]\n",
      "\u001b[32m2024-02-22 21:50:11.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 212 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.82it/s]\n",
      "\u001b[32m2024-02-22 21:50:14.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 213 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.67it/s]\n",
      "\u001b[32m2024-02-22 21:50:17.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 214 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.63it/s]\n",
      "\u001b[32m2024-02-22 21:50:20.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 215 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 31.61it/s]\n",
      "\u001b[32m2024-02-22 21:50:23.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 216 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 36.50it/s]\n",
      "\u001b[32m2024-02-22 21:50:26.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 217 / 1000, Loss: 0.31555888056755066, Val Loss: 0.7994824647903442, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 37.09it/s]\n",
      "\u001b[32m2024-02-22 21:50:29.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 218 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 17.02it/s]\n",
      "\u001b[32m2024-02-22 21:50:34.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 219 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 21.82it/s]\n",
      "\u001b[32m2024-02-22 21:50:40.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 220 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 33.70it/s]\n",
      "\u001b[32m2024-02-22 21:50:43.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 221 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.04it/s]\n",
      "\u001b[32m2024-02-22 21:50:46.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 222 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 30.24it/s]\n",
      "\u001b[32m2024-02-22 21:50:49.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 223 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.74it/s]\n",
      "\u001b[32m2024-02-22 21:50:53.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 224 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 30.21it/s]\n",
      "\u001b[32m2024-02-22 21:50:56.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 225 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:01<00:00, 34.63it/s]\n",
      "\u001b[32m2024-02-22 21:50:59.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 226 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:02<00:00, 32.61it/s]\n",
      "\u001b[32m2024-02-22 21:51:02.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mEpoch: 227 / 1000, Loss: 0.31555885076522827, Val Loss: 0.7994825839996338, Accuracy: 0.5390956194065002, Val Accuracy: 0.5502471169686985\u001b[0m\n",
      "\u001b[32m2024-02-22 21:51:03.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mEarly Stopping reached @ epoch = 227! Best Loss: 0.31555888056755066, Loss: 0.31555885076522827,Val Loss: 0.9438162446022034, Accuracy: 0.5390956194065002, Val Accuracy: 0.5560875512995896\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "my_net = Net(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE).to(device=DEVICE)\n",
    "train(net=my_net, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "d3a015b2-7b85-44b4-9476-700c7ef863db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 55.61%, loss = 0.94382\n"
     ]
    }
   ],
   "source": [
    "acc, loss = test(net=my_net)\n",
    "print(f\"{acc = :.2%}, {loss = :.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864a939-dfa4-4a58-ad14-c5d9f9878171",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "aa75fe18-911b-4709-aa18-4a6efca352c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "7fbcadb8-6d5a-49e7-86e2-e3212d0f9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_acc_loss_graph(model_name: str):\n",
    "\n",
    "    prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    colors = prop_cycle.by_key()['color']\n",
    "    color_map = {\"train\": colors[0], \"test\": colors[1]}\n",
    "    \n",
    "    contents = pd.read_csv(f\"outputs/models/{model_name}.log\", names=[\"name\", \"time\", \"epoch\", \"acc\", \"loss\", \"val_acc\", \"val_loss\"])\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "    ax1 = plt.subplot2grid((2, 1), (0, 0))\n",
    "    ax2 = plt.subplot2grid((2, 1), (1, 0), sharex=ax1)\n",
    "\n",
    "    ax1.plot(contents[\"epoch\"], contents[\"acc\"], label=\"acc\", color=color_map[\"train\"])\n",
    "    twinx1 = ax1#.twinx()\n",
    "    twinx1.plot(contents[\"epoch\"], contents[\"val_acc\"], label=\"val_acc\", color=color_map[\"test\"])\n",
    "    ax1.legend(loc=2)\n",
    "\n",
    "    ax2.plot(contents[\"epoch\"], contents[\"loss\"], label=\"loss\", color=color_map[\"train\"])\n",
    "    # ax2.set_yscale(\"log\")\n",
    "    ax2.legend(loc=2)\n",
    "    twinx2 = ax2#.twinx()\n",
    "    twinx2.plot(contents[\"epoch\"], contents[\"val_loss\"], label=\"val_loss\", color=color_map[\"test\"])\n",
    "    # twinx2.set_yscale(\"log\")\n",
    "    twinx2.legend(loc=1)\n",
    "\n",
    "    n = contents.shape[0] // 8\n",
    "    ax1.set_xticklabels(contents[\"epoch\"].tolist()[::n])\n",
    "    ax1.set_xticks([*range(0, contents.shape[0], n)])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "943f2efb-ed90-4a54-bcd1-18882c689205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomw1\\AppData\\Local\\Temp\\ipykernel_27160\\944549769.py:28: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(contents[\"epoch\"].tolist()[::n])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = f\"{Net.MODEL_TYPE}-model-latest\"\n",
    "create_acc_loss_graph(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ea71f-07cd-4af4-ab00-917586f93e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8ade4-646c-4da0-9fba-ed7405155a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46389e31-2674-4616-b56b-ac3a937de3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210acc76-cec1-47e8-9f1e-9ce1059688f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419fb54-9277-4dbd-b273-40ef5006ea5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931313e2-4d72-4a9e-8430-2416dc87b984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d633cb6-c852-4e6a-8633-a00086c36bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1f073-555b-488a-8261-7d0ec8de6c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5001e91-3e94-41d8-b5f3-12362638fe99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "d916cc9c-e447-4f2e-83e0-ea40e28c4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtr_train = [(torch.sum(X_train[i, -1, :-orig_y_total.shape[1]]) != 0) for i in range(X_train.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "c0f8aba8-e3a2-4cdf-ac07-0094a8de0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = get_prediction(net=my_net, X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "47cd8bd3-81e9-4b5e-841a-b8701ea03e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3841, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(output=y_train_hat[filtr_train], target=y_train[filtr_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "34b26500-fb2b-41ed-b081-2d613248799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3156, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(output=y_train_hat, target=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f1aea-d7cf-4edc-a6d7-b925917f5470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "f862b978-54c9-4b0a-84e3-61131f38bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtr_test = [(torch.sum(X_test[i, -1, :-orig_y_total.shape[1]]) != 0) for i in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "d8e0fea9-612f-4106-986f-b719d8a77920",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = get_prediction(net=my_net, X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "4ddb2060-ca6b-4a92-a077-795173f6a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9438, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(output=y_test_hat[filtr_test], target=y_test[filtr_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "f9465980-6ea6-4ce6-8751-8d74d0467b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7995, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss(output=y_test_hat, target=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40415c-34de-4268-b9bd-e6dbce4500c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "5d97fcda-a8fb-4dac-99ff-ce679ea300b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame([X_test[i][-1].detach().numpy() for i in range(X_test.shape[0]) if filtr_test[i]], columns=[col[1] for col in orig_X_total.columns])\n",
    "df = pd.concat([\n",
    "    pd.DataFrame([y_test[i].detach().numpy() for i in range(X_test.shape[0]) if filtr_test[i]], columns=orig_y_total.columns),\n",
    "    pd.DataFrame([y_test_hat[i].detach().numpy() for i in range(X_test.shape[0]) if filtr_test[i]], columns=[f\"{col}_pos\" for col in orig_y_total.columns]),\n",
    "    X_df,\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "c44d892c-3a16-484f-923d-b54965535607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45714285714285713"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[df[\"september_bear\"] == 1.0, \"SPY\"] > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "25599cf1-33ff-4078-8bfb-2b4b1d5c21b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585143658023827"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[df[\"september_bear\"] != 1.0, \"SPY\"] > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591685b1-512c-47cb-ac0c-20717ab44ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8156ee-0a4c-41ab-b692-491f2ab41101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06365600-92e7-4676-aaa6-fd70ddbdbbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
