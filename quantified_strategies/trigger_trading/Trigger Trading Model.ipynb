{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69c3e7d-27f7-4be8-8745-b7a350dc3452",
   "metadata": {},
   "source": [
    "# Trigger Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe98b6-e4d4-4e21-b87f-676f84f69805",
   "metadata": {},
   "source": [
    "### description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b93cdf4-d401-4593-8200-543ec347d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dff0bf5-aa13-4dfb-8a8a-da1ec7963e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker: str) -> pd.DataFrame:\n",
    "\n",
    "    INTERVALS = [\"1m\", \"2m\", \"5m\", \"15m\", \"30m\"]\n",
    "    intervals = utils.fetch_intervals()\n",
    "\n",
    "    pxs = []\n",
    "    for interval, from_date, to_date  in intervals:\n",
    "        \n",
    "        if interval not in INTERVALS:\n",
    "            continue\n",
    "\n",
    "        px = yf.download(ticker, start=from_date, end=to_date, interval=interval, progress=False)\n",
    "        px[\"interval\"] = interval\n",
    "        pxs.append(px)\n",
    "\n",
    "    px = pd.concat(pxs, axis=0)\n",
    "    px = px.sort_index()\n",
    "\n",
    "    px = px[\"Adj Close\"].to_frame(name=ticker)\n",
    "    \n",
    "    return px\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7ceab3b-acb2-4ca9-9b32-c8de67aec0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "TRIGGER_ASSETS = [\"GBPUSD=X\", \"CL=F\"]\n",
    "TRADE_ASSETS = [\"^FTSE\", \"EUEA.AS\"]\n",
    "\n",
    "ASSETS = TRIGGER_ASSETS + TRADE_ASSETS\n",
    "\n",
    "FORWARD_WINDOW = 30\n",
    "SEQUENCE_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410dfb2-725e-4b66-93f3-59c3a5bf2c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eab2e211-6329-4259-96e4-89d6c343a6af",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ca6b8d5-98dd-437c-b6b2-f9c2571ebfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBPUSD=X</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>^FTSE</th>\n",
       "      <th>EUEA.AS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:06:00+00:00</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:08:00+00:00</th>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:10:00+00:00</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:12:00+00:00</th>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:14:00+00:00</th>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>-0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:16:00+00:00</th>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:18:00+00:00</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:20:00+00:00</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:22:00+00:00</th>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 08:24:00+00:00</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GBPUSD=X      CL=F     ^FTSE   EUEA.AS\n",
       "Datetime                                                         \n",
       "2024-01-29 08:06:00+00:00  0.000114  0.000765  0.000394 -0.000530\n",
       "2024-01-29 08:08:00+00:00 -0.000114 -0.000764  0.000385  0.000212\n",
       "2024-01-29 08:10:00+00:00  0.000127 -0.000765  0.000101  0.000000\n",
       "2024-01-29 08:12:00+00:00 -0.000051  0.000638 -0.000653  0.000424\n",
       "2024-01-29 08:14:00+00:00 -0.000038 -0.000510 -0.000296 -0.000212\n",
       "2024-01-29 08:16:00+00:00 -0.000394  0.000638 -0.000123 -0.000318\n",
       "2024-01-29 08:18:00+00:00  0.000064  0.000255  0.000271  0.000425\n",
       "2024-01-29 08:20:00+00:00  0.000165 -0.000127 -0.000122 -0.000318\n",
       "2024-01-29 08:22:00+00:00 -0.000076 -0.000255  0.000497  0.000000\n",
       "2024-01-29 08:24:00+00:00  0.000064 -0.000637 -0.000330  0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([get_data(ticker=ticker) for ticker in ASSETS], axis=1)\n",
    "df[\"date\"] = df.index.date\n",
    "df = df.groupby(\"date\").ffill()\n",
    "df = df.dropna()\n",
    "df[\"date\"] = df.index.date\n",
    "ret = df.groupby(\"date\").pct_change().dropna()\n",
    "ret.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32f78141-56f8-4205-adfe-cc8d752bb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for i in range(SEQUENCE_LENGTH, ret.shape[0] - FORWARD_WINDOW):\n",
    "    timestamp = ret.index[i]\n",
    "    from_timestamp = ret.index[i - SEQUENCE_LENGTH + 1]\n",
    "    to_timestamp = ret.index[i + FORWARD_WINDOW]\n",
    "\n",
    "    if from_timestamp.date() != to_timestamp.date():\n",
    "        continue\n",
    "\n",
    "    before_data = ret.loc[(ret.index >= from_timestamp) & (ret.index <= timestamp)]\n",
    "    after_data = ret.loc[(ret.index > timestamp) & (ret.index <= to_timestamp)]\n",
    "\n",
    "    y = ((after_data[\"EUEA.AS\"] - after_data[\"^FTSE\"]) + 1).prod() - 1\n",
    "    X = before_data.T.values\n",
    "\n",
    "    y_list.append(y)\n",
    "    X_list.append(X)\n",
    "\n",
    "y = np.array(y_list)\n",
    "X = np.array(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf02cd0b-4b44-4573-a744-1a1cc6529ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18800, 4, 60)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58686be2-6bd5-4d4e-8b3a-fb49f0af2792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18800,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead23ec-f4e7-425d-a3f1-a5d3a2494d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81f9b9b5-4ee8-4592-9f5e-0bd7a21aa2e5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdf2078a-3f0c-4269-aff6-9e8485f3b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76636fbd-6216-4049-81b2-8708743b664a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "158a2c4c-2bdb-483c-a8ae-ac3c194ddb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-03 22:15:29.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_device\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mRunning on the CPU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(\"Running on the GPU\")\n",
    "        n_gpu = 0 # different if you have more than 1\n",
    "        assert n_gpu <= (torch.cuda.device_count() - 1)\n",
    "        logger.info(f\"Using gpu={n_gpu} out of {torch.cuda.device_count()}\")\n",
    "        device = torch.device(f\"cuda:{n_gpu}\")\n",
    "    else:\n",
    "        logger.info(\"Running on the CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=112, out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db93c161-c0ac-4d11-8d53-fc538e737a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46bf2db3-e0ee-4ba2-8699-34b0d5c742a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE_SIZE = 128\n",
    "\n",
    "# X_tensor = torch.tensor(X[:SAMPLE_SIZE], dtype=torch.float32)\n",
    "# X_tensor = X_tensor.reshape(SAMPLE_SIZE, 1, X_tensor.shape[1], X_tensor.shape[2])\n",
    "# y_tensor = torch.tensor(y[:SAMPLE_SIZE], dtype=torch.float32)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "X_tensor = X_tensor.reshape(X_tensor.shape[0], 1, X_tensor.shape[1], X_tensor.shape[2])\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d8e0aba-dda5-4c5a-8506-961abcc1f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor.shape = torch.Size([18800, 1, 4, 60])\n",
      "y_tensor.shape = torch.Size([18800])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_tensor.shape = }\")\n",
    "print(f\"{y_tensor.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73cf213a-a23a-4bbc-8d78-bd79f80ac5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f269464d-4f70-445f-968a-b21fc749b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, train_size=0.7, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bd4f90d-c044-4928-b599-ea95a3318cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([13160, 1, 4, 60])\n",
      "X_test.shape = torch.Size([5640, 1, 4, 60])\n",
      "y_train.shape = torch.Size([13160])\n",
      "y_test.shape = torch.Size([5640])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{X_test.shape = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{y_test.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3659c2b0-05e9-4bf5-af2c-ddb7ebcfcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Loss function with criterion\n",
    "criterion = nn.MSELoss()\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67bce37c-4986-4cfe-93c7-02e6162dbb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5640x232 and 112x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 29\u001b[0m y_test_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m loss_test \u001b[38;5;241m=\u001b[39m criterion(y_test_hat, y_test)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 38\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5640x232 and 112x32)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    for i in range(0, X_train.shape[0] - BATCH_SIZE, BATCH_SIZE):\n",
    "            \n",
    "        # Move tensors to the configured device\n",
    "        batch_X = X_train[i:(i+BATCH_SIZE)].to(device=DEVICE)\n",
    "        batch_y = y_train[i:(i+BATCH_SIZE)].to(device=DEVICE)\n",
    "\n",
    "        if batch_X.shape != BATCH_SIZE:\n",
    "            continue\n",
    "        \n",
    "        # Forward pass\n",
    "        y_hat = net(batch_X)\n",
    "        loss = criterion(y_hat, batch_y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"hi\")\n",
    "    net.eval()\n",
    "    y_test_hat = net(X_test)\n",
    "    loss_test = criterion(y_test_hat, y_test)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {loss}, Val Loss: {loss_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f40ea-49a6-4ab7-87c1-411c68495331",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = net(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba81ab0-198a-4079-83b0-c595b67e1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat[y_train_hat > 1 / 100_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edb305-24e5-4d94-880b-65660b2075e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e8376f6-db28-49ac-813f-0e9e45346882",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5640x232 and 112x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 38\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\quantified-strategies-wFBlb7GR-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5640x232 and 112x32)"
     ]
    }
   ],
   "source": [
    "net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d1a8e-2079-4807-ad9b-31a82e40e262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74a846-8353-4651-aedf-809cbe691c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b159aa-3ec6-458c-9170-6738fde6014f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb703da-0067-4a1a-9d57-1b0db847ecc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df9f1c-bff1-4193-a10f-bdcf323f0cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6499453-8201-4466-93c8-83ce262dd427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f965075-f7fb-48bb-bc27-2c48b2ea2f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
